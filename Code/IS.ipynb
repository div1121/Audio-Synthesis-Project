{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "IS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn4hQJg_A7Gy"
      },
      "source": [
        "!pip install tensorflow_io\n",
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqCOVrusC3do"
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas\n",
        "import tensorflow_datasets as tfds\n",
        "import time\n",
        "import librosa.display as lidp\n",
        "import tensorflow_io as tfio\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import Conv1DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.constraints import Constraint\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rs0ZkrNHXGD"
      },
      "source": [
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aLgKpjuC6gJ"
      },
      "source": [
        "data, info = tfds.load('nsynth', try_gcs=True, split='train', with_info=True)\n",
        "assert isinstance(data, tf.data.Dataset)\n",
        "#get data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYhIv6IRBm4C"
      },
      "source": [
        "testdata, info = tfds.load('nsynth', try_gcs=True, split='test', with_info=True)\n",
        "assert isinstance(testdata, tf.data.Dataset)\n",
        "print(len(testdata))\n",
        "test_x = np.array([])\n",
        "test_y = np.array([])\n",
        "count = 0\n",
        "for i in testdata.take(4096):\n",
        "\t# select images\n",
        "  sound = i[\"audio\"]\n",
        "  sound = sound[0:16384].numpy()\n",
        "  test_x = np.append(test_x,sound) \n",
        "  # generate class labels, -1 for 'real'\n",
        "  label = i[\"instrument\"][\"family\"]\n",
        "  c = label.numpy()\n",
        "  #print(c)\n",
        "  reallabel = np.zeros([11])\n",
        "  reallabel[c] = 1\n",
        "  test_y = np.append(test_y,reallabel)\n",
        "  print(count)\n",
        "  count += 1\n",
        "print(test_x)\n",
        "print(test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOr1me9xHmFN"
      },
      "source": [
        "test_x = np.reshape(test_x,(4096,16384,1))\n",
        "test_y = np.reshape(test_y,(4096,11))\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW9nNaOhW3Hg"
      },
      "source": [
        "# image size\n",
        "sound_size = 16384\n",
        "channels = 1\n",
        "sound_shape = (sound_size, channels)    # (16384,1)\n",
        "\n",
        "batch_size = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOKpq9a4nWaG"
      },
      "source": [
        "dataset = data.shuffle(batch_size*16).batch(batch_size)\n",
        "total = len(dataset)\n",
        "dataset = data.shuffle(batch_size*16).batch(batch_size).repeat()\n",
        "db_iter = iter(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7UD-N7fnDWK"
      },
      "source": [
        "for i in range(1):\n",
        "  batch = next(db_iter)\n",
        "  label = batch[\"instrument\"][\"family\"]\n",
        "  c = label.numpy()\n",
        "  print(c)\n",
        "  reallabel = np.zeros([label.shape[0],11])\n",
        "  reallabel[np.arange(reallabel.shape[0]),c] = 1\n",
        "  print(reallabel)\n",
        "  output = tf.convert_to_tensor(reallabel)\n",
        "  print(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgMMj9TR8N0t"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#login your dirve so that you can save model data for later training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTUPQNVTacVc"
      },
      "source": [
        "def conv_block(\n",
        "    x,\n",
        "    filters,\n",
        "    activation,\n",
        "    kernel_size=25,\n",
        "    strides=4,\n",
        "    padding=\"same\",\n",
        "    use_bias=True,\n",
        "    use_bn=False,\n",
        "    use_dropout=False,\n",
        "    drop_value=0.5,\n",
        "):\n",
        "    x = layers.Conv1D(\n",
        "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
        "    )(x)\n",
        "    if use_bn:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = activation(x)\n",
        "    if use_dropout:\n",
        "        x = layers.Dropout(drop_value)(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCeI0TlnapT0"
      },
      "source": [
        "def get_discriminator_model(d,c):\n",
        "    input = layers.Input(shape=sound_shape)\n",
        "    x = conv_block(\n",
        "        input,\n",
        "        d,\n",
        "        kernel_size=25,\n",
        "        strides=4,\n",
        "        use_bn=True,\n",
        "        use_bias=True,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    x = layers.MaxPooling1D(pool_size=4,strides=1,padding='same')(x)\n",
        "    x = conv_block(\n",
        "        x,\n",
        "        2*d,\n",
        "        kernel_size=25,\n",
        "        strides=4,\n",
        "        use_bn=True,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_bias=True,\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    x = layers.MaxPooling1D(pool_size=4,strides=1,padding='same')(x)\n",
        "    x = conv_block(\n",
        "        x,\n",
        "        4*d,\n",
        "        kernel_size=25,\n",
        "        strides=4,\n",
        "        use_bn=True,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_bias=True,\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    x = layers.MaxPooling1D(pool_size=4,strides=1,padding='same')(x)\n",
        "    x = conv_block(\n",
        "        x,\n",
        "        8*d,\n",
        "        kernel_size=25,\n",
        "        strides=4,\n",
        "        use_bn=True,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_bias=True,\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    x = layers.MaxPooling1D(pool_size=4,strides=1,padding='same')(x)\n",
        "    x = conv_block(\n",
        "        x,\n",
        "        16*d,\n",
        "        kernel_size=25,\n",
        "        strides=4,\n",
        "        use_bn=True,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_bias=True,\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    x = layers.MaxPooling1D(pool_size=4,strides=1,padding='same')(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(11,activation='softmax')(x)\n",
        "\n",
        "    d_model = keras.models.Model(input, x, name=\"discriminator\")\n",
        "    return d_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ieh1W9Y5d4iP"
      },
      "source": [
        "d_model = get_discriminator_model(64,1)\n",
        "d_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ufl2lPZ9vDY"
      },
      "source": [
        "def plot_history(d_hist, epoch):\n",
        "  # plot history\n",
        "  plt.plot(d_hist, label='crit')\n",
        "  plt.legend()\n",
        "  plt.savefig('/content/gdrive/My Drive/IS/plot_line_plot_loss_{:04d}.png'.format(epoch))\n",
        "  plt.close()\n",
        "  with open(\"/content/gdrive/My Drive/IS/derror.txt\", \"w\") as fp:  \n",
        "    json.dump(d_hist, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MF46Ieu2B3H"
      },
      "source": [
        "d_hist, g_hist = list(), list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVV8xMc9IAWU"
      },
      "source": [
        "with open(\"/content/gdrive/My Drive/IS/derror.txt\", \"r\") as fp:  \n",
        "  d_hist = json.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AWFwICP8Ttb"
      },
      "source": [
        "discriminator_optimizer = keras.optimizers.Adam(\n",
        "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DECrUI1Mk37h"
      },
      "source": [
        "d_model.compile(optimizer=discriminator_optimizer,loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmP5-K89m4Gq"
      },
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tbatch = next(dataset)\n",
        "\t# select images\n",
        "\tsound = batch[\"audio\"]\n",
        "\tsound = sound[:,0:16384]\n",
        "\tX = tf.reshape(sound,[sound.shape[0],16384,1])\n",
        "\t# generate class labels, -1 for 'real'\n",
        "\tlabel = batch[\"instrument\"][\"family\"]\n",
        "\tc = label.numpy()\n",
        "\treallabel = np.zeros([label.shape[0],11])\n",
        "\treallabel[np.arange(reallabel.shape[0]),c] = 1\n",
        "\t#print(reallabel)\n",
        "\ty = tf.convert_to_tensor(reallabel)\n",
        "\treturn X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SwgW8NcmWga"
      },
      "source": [
        "# train the critic\n",
        "def train(d_model, dataset,test_x,test_y, n_epochs=5, n_batch=64):\n",
        "\tfor i in range(n_epochs):\n",
        "\t\t# get randomly selected 'real' samples\n",
        "\t\tX_real, y_real = generate_real_samples(dataset, n_batch)\n",
        "\t\t# update critic model weights\n",
        "\t\td_loss = d_model.train_on_batch(X_real, y_real)\n",
        "\t\td_hist.append(d_loss[0])\n",
        "\t\t# summarize loss on this batch\n",
        "\t\tprint('>%d, d=%.3f' % (i+1, d_loss[0]))\n",
        "\t\t# evaluate the model performance every 'epoch'\n",
        "\t\tif (i+1) % (4000) == 0:\n",
        "\t\t\tcheckpoint.save(file_prefix = checkpoint_prefix)\n",
        "\t\t\tplot_history(d_hist, len(d_hist))\n",
        "\t\t\td_model.evaluate(test_x,test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq7ibAze8qh7"
      },
      "source": [
        "checkpoint_dir = '/content/gdrive/My Drive/IS'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(d_model=d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsFD44Lv9B3b"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfDWb7tz9EJV"
      },
      "source": [
        "checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPhkZR8jK42X"
      },
      "source": [
        "plot_history(d_hist,-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj6NLyIjgACZ"
      },
      "source": [
        "d_model.evaluate(test_x,test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_csYx50ntW5G"
      },
      "source": [
        "d_model.save(\"/content/gdrive/My Drive/IS/rmodel\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJzqvYn-uRSt"
      },
      "source": [
        "model = keras.models.load_model('/content/gdrive/My Drive/IS/rmodel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FeIQZjwKTIH"
      },
      "source": [
        "train(d_model,db_iter,test_x,test_y,50001)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}