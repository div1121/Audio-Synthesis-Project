{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "EVA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn4hQJg_A7Gy"
      },
      "source": [
        "!pip install tensorflow_io\n",
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqCOVrusC3do"
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas\n",
        "import tensorflow_datasets as tfds\n",
        "import time\n",
        "import librosa.display as lidp\n",
        "import tensorflow_io as tfio\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import Conv1DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.constraints import Constraint\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from numpy import cov\n",
        "from numpy import trace\n",
        "from numpy import iscomplexobj\n",
        "from numpy import asarray\n",
        "from numpy.random import randint\n",
        "from math import floor\n",
        "from numpy import ones\n",
        "from numpy import expand_dims\n",
        "from numpy import log\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import exp\n",
        "from scipy.linalg import sqrtm\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rs0ZkrNHXGD"
      },
      "source": [
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aLgKpjuC6gJ"
      },
      "source": [
        "data, info = tfds.load('nsynth', try_gcs=True, split='train', with_info=True)\n",
        "assert isinstance(data, tf.data.Dataset)\n",
        "#get data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdxlYIjRAb3W"
      },
      "source": [
        "data = data.shuffle(100*16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYhIv6IRBm4C"
      },
      "source": [
        "testdata, info = tfds.load('nsynth', try_gcs=True, split='test', with_info=True)\n",
        "assert isinstance(testdata, tf.data.Dataset)\n",
        "print(len(testdata))\n",
        "test_x = np.array([])\n",
        "test_y = np.array([])\n",
        "count = 0\n",
        "for i in data.take(1000):\n",
        "\t# select images\n",
        "  sound = i[\"audio\"]\n",
        "  sound = sound[0:16384].numpy()\n",
        "  test_x = np.append(test_x,sound) \n",
        "  # generate class labels, -1 for 'real'\n",
        "  label = i[\"instrument\"][\"family\"]\n",
        "  c = label.numpy()\n",
        "  #print(c)\n",
        "  reallabel = np.zeros([11])\n",
        "  reallabel[c] = 1\n",
        "  test_y = np.append(test_y,reallabel)\n",
        "  print(count)\n",
        "  count += 1\n",
        "print(test_x)\n",
        "print(test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOr1me9xHmFN"
      },
      "source": [
        "test_x = np.reshape(test_x,(1000,16384,1))\n",
        "test_y = np.reshape(test_y,(1000,11))\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLaivLzbUq7r"
      },
      "source": [
        "is_avg, is_std = calculate_inception_score(test_x)\n",
        "print('score', is_avg, is_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qay0tgzxYs6I"
      },
      "source": [
        "r_x = np.array([])\n",
        "r_y = np.array([])\n",
        "count = 0\n",
        "for i in testdata.take(1000):\n",
        "\t# select images\n",
        "  sound = i[\"audio\"]\n",
        "  sound = sound[0:16384].numpy()\n",
        "  r_x = np.append(r_x,sound) \n",
        "  print(count)\n",
        "  count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdlISVeiY5Zm"
      },
      "source": [
        "r_x = np.reshape(r_x,(1000,16384,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEsdR_nUZVSV"
      },
      "source": [
        "is_avg, is_std = calculate_inception_score(r_x)\n",
        "print('score', is_avg, is_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgMMj9TR8N0t"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#login your dirve so that you can save model data for later training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmP5-K89m4Gq"
      },
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tbatch = next(dataset)\n",
        "\t# select images\n",
        "\tsound = batch[\"audio\"]\n",
        "\tsound = sound[:,0:16384]\n",
        "\tX = tf.reshape(sound,[sound.shape[0],16384,1])\n",
        "\t# generate class labels, -1 for 'real'\n",
        "\tlabel = batch[\"instrument\"][\"family\"]\n",
        "\tc = label.numpy()\n",
        "\treallabel = np.zeros([label.shape[0],11])\n",
        "\treallabel[np.arange(reallabel.shape[0]),c] = 1\n",
        "\t#print(reallabel)\n",
        "\ty = tf.convert_to_tensor(reallabel)\n",
        "\treturn X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nil7VyNTVYc"
      },
      "source": [
        "def calculate_inception_score(images, n_split=10, eps=1E-16):\n",
        "\t# load model\n",
        "\tmodel = keras.models.load_model('/content/gdrive/My Drive/rmodel')\n",
        "\t# predict class probabilities for images\n",
        "\tyhat = model.predict(images)\n",
        "\t# enumerate splits of images/predictions\n",
        "\t#print(yhat)\n",
        "\tscores = list()\n",
        "\tn_part = floor(images.shape[0] / n_split)\n",
        "\tfor i in range(n_split):\n",
        "\t\t# retrieve p(y|x)\n",
        "\t\tix_start, ix_end = i * n_part, i * n_part + n_part\n",
        "\t\tp_yx = yhat[ix_start:ix_end]\n",
        "\t\t# calculate p(y)\n",
        "\t\tp_y = expand_dims(p_yx.mean(axis=0), 0)\n",
        "\t\t# calculate KL divergence using log probabilities\n",
        "\t\tkl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
        "\t\t# sum over classes\n",
        "\t\tsum_kl_d = kl_d.sum(axis=1)\n",
        "\t\t# average over images\n",
        "\t\tavg_kl_d = mean(sum_kl_d)\n",
        "\t\t# undo the log\n",
        "\t\tis_score = exp(avg_kl_d)\n",
        "\t\t# store\n",
        "\t\tscores.append(is_score)\n",
        "\t# average across images\n",
        "\tis_avg, is_std = mean(scores), std(scores)\n",
        "\treturn is_avg, is_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRrPDlQQViNN"
      },
      "source": [
        "images = tf.random.normal(shape=(5000, 100))\n",
        "print('loaded', images.shape)\n",
        "generator = keras.models.load_model('/content/gdrive/My Drive/amodel')\n",
        "audio = generator.predict(images)\n",
        "#print(audio)\n",
        "# calculate inception score\n",
        "is_avg, is_std = calculate_inception_score(audio)\n",
        "print('score', is_avg, is_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qofYqSEo7b1p"
      },
      "source": [
        "images = tf.random.normal(shape=(5000, 100))\n",
        "print('loaded', images.shape)\n",
        "generator = keras.models.load_model('/content/gdrive/My Drive/bmodel')\n",
        "audio = generator.predict(images)\n",
        "print(audio)\n",
        "# calculate inception score\n",
        "is_avg, is_std = calculate_inception_score(audio)\n",
        "print('score', is_avg, is_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DlNMo8W72un"
      },
      "source": [
        "images = tf.random.normal(shape=(5000, 100))\n",
        "print('loaded', images.shape)\n",
        "generator = keras.models.load_model('/content/gdrive/My Drive/cmodel')\n",
        "audio = generator.predict(images)\n",
        "print(audio)\n",
        "# calculate inception score\n",
        "is_avg, is_std = calculate_inception_score(audio)\n",
        "print('score', is_avg, is_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to2eRkP296bB"
      },
      "source": [
        "def invert_spectra_griffin_lim(X_mag, nfft, nhop, ngl):\n",
        "    x = tf.signal.inverse_stft(X_mag,nfft,nhop)\n",
        "    x = x[:, :16384]\n",
        "    #print(x.shape)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzrfOTaV9e5j"
      },
      "source": [
        "def f_to_t(X_norm ,ngl=16):\n",
        "  x = invert_spectra_griffin_lim(X_norm,256,128,ngl)\n",
        "  x = tf.reshape(x, [-1, 16384, 1])\n",
        "  #print(x.shape)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8llsfhPV8R1X"
      },
      "source": [
        "images = tf.random.normal(shape=(5000, 100))\n",
        "print('loaded', images.shape)\n",
        "generator = keras.models.load_model('/content/gdrive/My Drive/dmodel')\n",
        "predictions = generator.predict(images)\n",
        "a = predictions[:,:,:,0]\n",
        "b = predictions[:,:,:,1]\n",
        "r = tf.complex(a, b)\n",
        "audio = f_to_t(r)\n",
        "#print(audio)\n",
        "# calculate inception score\n",
        "is_avg, is_std = calculate_inception_score(audio)\n",
        "print('score', is_avg, is_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ikGTEAnXSzD"
      },
      "source": [
        "def calculate_fid(model, images1, images2):\n",
        "\t# calculate activations\n",
        "\tact1 = model.predict(images1)\n",
        "\tact2 = model.predict(images2)\n",
        "\t# calculate mean and covariance statistics\n",
        "\tmu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
        "\tmu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
        "\t# calculate sum squared difference between means\n",
        "\tssdiff = np.sum((mu1 - mu2)**2.0)\n",
        "\t# calculate sqrt of product between cov\n",
        "\tcovmean = sqrtm(sigma1.dot(sigma2))\n",
        "\t# check and correct imaginary numbers from sqrt\n",
        "\tif iscomplexobj(covmean):\n",
        "\t\tcovmean = covmean.real\n",
        "\t# calculate score\n",
        "\tfid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "\treturn fid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T9nLGj6DCXZ"
      },
      "source": [
        "model = keras.models.load_model('/content/gdrive/My Drive/rmodel')\n",
        "print(model.summary())\n",
        "model2 = keras.models.Model(inputs=model.input, outputs=model.get_layer(\"flatten\").output)\n",
        "print(model2.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tViW49HX2MU"
      },
      "source": [
        "images1 = test_x\n",
        "print(images1.shape)\n",
        "generator = keras.models.load_model('/content/gdrive/My Drive/amodel')\n",
        "z = tf.random.normal(shape=(2, 100))\n",
        "images2 = generator.predict(z)\n",
        "# fid between images1 and images1\n",
        "fid = calculate_fid(model2, images1, images1)\n",
        "print('FID (same): %.3f' % fid)\n",
        "# fid between images1 and images2\n",
        "fid = calculate_fid(model2, images1, images2)\n",
        "print('FID (different): %.3f' % fid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZgfWtJAaxrH"
      },
      "source": [
        "def nn_dist(train_set, query_set, exclude_self):\n",
        "  # Flatten\n",
        "  train_set = np.reshape(train_set, [train_set.shape[0], -1])\n",
        "  query_set = np.reshape(query_set, [query_set.shape[0], -1])\n",
        "\n",
        "  # Create and query model\n",
        "  print('Creating model')\n",
        "  start = time.time()\n",
        "  model = NearestNeighbors(n_neighbors=2 if exclude_self else 1, algorithm='ball_tree').fit(train_set)\n",
        "  print('Took {} seconds'.format(time.time() - start))\n",
        "\n",
        "  print('Querying model')\n",
        "  start = time.time()\n",
        "  dists, _ = model.kneighbors(query_set)\n",
        "  print('Took {} seconds'.format(time.time() - start))\n",
        "\n",
        "  # If specified, exclude first nearest neighbor (duplicate) if it is nonzero\n",
        "  if exclude_self:\n",
        "    dists_excluded = []\n",
        "    for dist0, dist1 in dists:\n",
        "      if dist0 == 0:\n",
        "        dists_excluded.append(dist1)\n",
        "      else:\n",
        "        dists_excluded.append(dist0)\n",
        "    dists = dists_excluded\n",
        "  else:\n",
        "    dists = dists[:, 0]\n",
        "\n",
        "  return np.mean(dists), np.std(dists)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovW98WB3IzJB"
      },
      "source": [
        "generator = keras.models.load_model('/content/gdrive/My Drive/amodel')\n",
        "z = tf.random.normal(shape=(1000, 100))\n",
        "query_set = generator.predict(z)\n",
        "train_set = test_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipVe0mndKWfp"
      },
      "source": [
        "generator = keras.models.load_model('/content/gdrive/My Drive/bmodel')\n",
        "z = tf.random.normal(shape=(1000, 100))\n",
        "query_set = generator.predict(z)\n",
        "train_set = test_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz4t93NvKbSN"
      },
      "source": [
        "generator = keras.models.load_model('/content/gdrive/My Drive/cmodel')\n",
        "z = tf.random.normal(shape=(1000, 100))\n",
        "query_set = generator.predict(z)\n",
        "train_set = test_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhhMTxXqKdXX"
      },
      "source": [
        "generator = keras.models.load_model('/content/gdrive/My Drive/dmodel')\n",
        "z = tf.random.normal(shape=(1000, 100))\n",
        "predictions = generator.predict(z)\n",
        "a = predictions[:,:,:,0]\n",
        "b = predictions[:,:,:,1]\n",
        "r = tf.complex(a, b)\n",
        "query_set = f_to_t(r)\n",
        "train_set = test_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODS3dZVxZwdz"
      },
      "source": [
        "query_set = r_x\n",
        "train_set = test_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eZCUlcGa18u"
      },
      "source": [
        "mean, std = nn_dist(query_set, query_set, True)\n",
        "print('Similarity: {} +- {}'.format(mean, std))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsaToMbsJw_Y"
      },
      "source": [
        "mean, std = nn_dist(train_set, query_set, False)\n",
        "print('Similarity: {} +- {}'.format(mean, std))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}