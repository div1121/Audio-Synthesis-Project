{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "WGANGP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn4hQJg_A7Gy"
      },
      "source": [
        "!pip install tensorflow_io\n",
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqCOVrusC3do"
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas\n",
        "import tensorflow_datasets as tfds\n",
        "import time\n",
        "import librosa.display as lidp\n",
        "import tensorflow_io as tfio\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import Conv1DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.constraints import Constraint\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rs0ZkrNHXGD"
      },
      "source": [
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aLgKpjuC6gJ"
      },
      "source": [
        "data, info = tfds.load('nsynth', try_gcs=True, split='train', with_info=True)\n",
        "assert isinstance(data, tf.data.Dataset)\n",
        "#get data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW9nNaOhW3Hg"
      },
      "source": [
        "# image size\n",
        "sound_size = 16384\n",
        "channels = 1\n",
        "sound_shape = (sound_size, channels)    # (16384,3)\n",
        "\n",
        "# z(latent variable) size\n",
        "z_dim = 100\n",
        "z_shape = (z_dim,)\n",
        "\n",
        "# gradient penalty coefficient \"Î»\"\n",
        "penaltyLambda = 10    \n",
        "\n",
        "# critic(discriminator) iterations per generator iteration\n",
        "trainRatio = 5\n",
        "\n",
        "batch_size = 64\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOKpq9a4nWaG"
      },
      "source": [
        "dataset = data.shuffle(batch_size*16).batch(batch_size)\n",
        "total = len(dataset)\n",
        "dataset = data.shuffle(batch_size*16).batch(batch_size).repeat()\n",
        "db_iter = iter(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgMMj9TR8N0t"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#login your dirve so that you can save model data for later training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTUPQNVTacVc"
      },
      "source": [
        "def conv_block(\n",
        "    x,\n",
        "    filters,\n",
        "    activation,\n",
        "    kernel_size=25,\n",
        "    strides=4,\n",
        "    padding=\"same\",\n",
        "    use_bias=True,\n",
        "    use_bn=False,\n",
        "    use_dropout=False,\n",
        "    drop_value=0.5,\n",
        "):\n",
        "    x = layers.Conv1D(\n",
        "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
        "    )(x)\n",
        "    if use_bn:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = activation(x)\n",
        "    if use_dropout:\n",
        "        x = layers.Dropout(drop_value)(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCeI0TlnapT0"
      },
      "source": [
        "def get_discriminator_model(d,c):\n",
        "    input = layers.Input(shape=sound_shape)\n",
        "    x = conv_block(\n",
        "        input,\n",
        "        d,\n",
        "        kernel_size=25,\n",
        "        strides=4,\n",
        "        use_bn=False,\n",
        "        use_bias=True,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    x = conv_block(\n",
        "        x,\n",
        "        2*d,\n",
        "        kernel_size=25,\n",
        "        strides=4,\n",
        "        use_bn=False,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_bias=True,\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    x = conv_block(\n",
        "        x,\n",
        "        4*d,\n",
        "        kernel_size=25,\n",
        "        strides=4,\n",
        "        use_bn=False,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_bias=True,\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    x = conv_block(\n",
        "        x,\n",
        "        8*d,\n",
        "        kernel_size=25,\n",
        "        strides=4,\n",
        "        use_bn=False,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_bias=True,\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    x = conv_block(\n",
        "        x,\n",
        "        16*d,\n",
        "        kernel_size=25,\n",
        "        strides=4,\n",
        "        use_bn=False,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_bias=True,\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(1)(x)\n",
        "\n",
        "    d_model = keras.models.Model(input, x, name=\"discriminator\")\n",
        "    return d_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ieh1W9Y5d4iP"
      },
      "source": [
        "d_model = get_discriminator_model(64,1)\n",
        "d_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOhKXTiMfinW"
      },
      "source": [
        "def upsample_block(\n",
        "    x,\n",
        "    filters,\n",
        "    activation,\n",
        "    kernel_size=25,\n",
        "    strides=4,\n",
        "    up_size=(2, 2),\n",
        "    padding=\"same\",\n",
        "    use_bn=False,\n",
        "    use_bias=True,\n",
        "    use_dropout=False,\n",
        "    drop_value=0.3,\n",
        "):\n",
        "    x = layers.Conv1DTranspose(\n",
        "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
        "    )(x)\n",
        "\n",
        "    if use_bn:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    if activation:\n",
        "        x = activation(x)\n",
        "    if use_dropout:\n",
        "        x = layers.Dropout(drop_value)(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVLfT1O1gU5c"
      },
      "source": [
        "def get_generator_model(d,c):\n",
        "    noise = layers.Input(shape=(z_dim,))\n",
        "    x = layers.Dense(d * 256)(noise)\n",
        "    # x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Reshape((16, 16*d))(x)\n",
        "    x = upsample_block(\n",
        "        x,\n",
        "        8*d,\n",
        "        layers.LeakyReLU(0.2),\n",
        "        strides=4,\n",
        "        use_bias=True,\n",
        "        use_bn=False,\n",
        "        padding=\"same\",\n",
        "        use_dropout=False,\n",
        "    )\n",
        "    x = upsample_block(\n",
        "        x,\n",
        "        4*d,\n",
        "        layers.LeakyReLU(0.2),\n",
        "        strides=4,\n",
        "        use_bias=True,\n",
        "        use_bn=False,\n",
        "        padding=\"same\",\n",
        "        use_dropout=False,\n",
        "    )\n",
        "    x = upsample_block(\n",
        "        x,\n",
        "        2*d,\n",
        "        layers.LeakyReLU(0.2),\n",
        "        strides=4,\n",
        "        use_bias=True,\n",
        "        use_bn=False,\n",
        "        padding=\"same\",\n",
        "        use_dropout=False,\n",
        "    )\n",
        "    x = upsample_block(\n",
        "        x,\n",
        "        d,\n",
        "        layers.LeakyReLU(0.2),\n",
        "        strides=4,\n",
        "        use_bias=True,\n",
        "        use_bn=False,\n",
        "        padding=\"same\",\n",
        "        use_dropout=False,\n",
        "    )\n",
        "    x = upsample_block(\n",
        "        x, c, layers.Activation(\"tanh\"), strides=4, use_bias=True, use_bn=False\n",
        "    )\n",
        "\n",
        "    g_model = keras.models.Model(noise, x, name=\"generator\")\n",
        "    return g_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpTzYtyyi69q"
      },
      "source": [
        "g_model = get_generator_model(64,1)\n",
        "g_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g15bjk397cB"
      },
      "source": [
        "def generate_and_save_images(model, epoch):\n",
        "  #checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  test_input = tf.random.normal(shape=(16, 100))\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig, axes = plt.subplots(16,1,figsize=(15, 30))\n",
        "  for i in range(predictions.shape[0]):\n",
        "    x = np.linspace(0,16384,16384)\n",
        "    #print(predictions[i,:,0])\n",
        "    k = np.reshape(predictions[i,:,0],(16384))\n",
        "    display.display(display.Audio(k, rate=16000))\n",
        "    axes[i].plot(x,k)\n",
        "\n",
        "  plt.savefig('/content/gdrive/My Drive/WGANGP/sound_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n",
        "#check output data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ufl2lPZ9vDY"
      },
      "source": [
        "def plot_history(d_hist, g_hist, epoch):\n",
        "  # plot history\n",
        "  plt.plot(d_hist, label='crit')\n",
        "  plt.plot(g_hist, label='gen')\n",
        "  plt.legend()\n",
        "  plt.savefig('/content/gdrive/My Drive/WGANGP/plot_line_plot_loss_{:04d}.png'.format(epoch))\n",
        "  plt.close()\n",
        "  with open(\"/content/gdrive/My Drive/WGANGP/derror.txt\", \"w\") as fp:  \n",
        "    json.dump(d_hist, fp)\n",
        "  with open(\"/content/gdrive/My Drive/WGANGP/gerror.txt\", \"w\") as fp:  \n",
        "    json.dump(g_hist, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MF46Ieu2B3H"
      },
      "source": [
        "d_hist, g_hist = list(), list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVV8xMc9IAWU"
      },
      "source": [
        "with open(\"/content/gdrive/My Drive/WGANGP/derror.txt\", \"r\") as fp:  \n",
        "  d_hist = json.load(fp)\n",
        "with open(\"/content/gdrive/My Drive/WGANGP/gerror.txt\", \"r\") as fp:  \n",
        "  g_hist = json.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duXJ7rdzs-fX"
      },
      "source": [
        "class WGAN(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        discriminator,\n",
        "        generator,\n",
        "        latent_dim,\n",
        "        discriminator_extra_steps=3,\n",
        "        gp_weight=10.0,\n",
        "    ):\n",
        "        super(WGAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.d_steps = discriminator_extra_steps\n",
        "        self.gp_weight = gp_weight\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
        "        super(WGAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_loss_fn = d_loss_fn\n",
        "        self.g_loss_fn = g_loss_fn\n",
        "\n",
        "    def gradient_penalty(self, batch_size, real, fake):\n",
        "        alpha = tf.random.normal([batch_size, 1, 1], 0.0, 1.0)\n",
        "        diff = fake - real\n",
        "        interpolated = real + alpha * diff\n",
        "        with tf.GradientTape() as gp_tape:\n",
        "            gp_tape.watch(interpolated)\n",
        "            pred = self.discriminator(interpolated, training=True)\n",
        "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
        "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2]))\n",
        "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
        "        return gp\n",
        "\n",
        "    def train(self, db_iter, b_size=64, n_epoch=2, total=4519):\n",
        "\n",
        "        # Get the batch size\n",
        "        batch_size = b_size\n",
        "        bat_per_epo = total\n",
        "        n_steps = bat_per_epo * n_epoch\n",
        "\n",
        "        # 1. Train the generator and get the generator loss\n",
        "        # 2. Train the discriminator and get the discriminator loss\n",
        "        # 3. Calculate the gradient penalty\n",
        "        # 4. Multiply this gradient penalty with a constant weight factor\n",
        "        # 5. Add gradient penalty to the discriminator loss\n",
        "        # 6. Return generator and discriminator losses as a loss dictionary.\n",
        "\n",
        "        for j in range(n_steps): \n",
        "            for i in range(self.d_steps):\n",
        "                batch = next(db_iter)\n",
        "                sound = batch[\"audio\"]\n",
        "                sound = sound[:,0:16384]\n",
        "                real_sound = tf.reshape(sound,[sound.shape[0],16384,1])\n",
        "\n",
        "                # Get the latent vector\n",
        "                random_latent_vectors = tf.random.normal(\n",
        "                  shape=(sound.shape[0], self.latent_dim)\n",
        "                )\n",
        "                with tf.GradientTape() as tape:\n",
        "                  fake_sound = self.generator(random_latent_vectors, training=True)\n",
        "                  fake_logits = self.discriminator(fake_sound, training=True)\n",
        "                  real_logits = self.discriminator(real_sound, training=True)\n",
        "\n",
        "                  # Calculate discriminator loss using fake and real logits\n",
        "                  d_cost = self.d_loss_fn(real=real_logits, fake=fake_logits)\n",
        "                  # Calculate the gradient penalty\n",
        "                  gp = self.gradient_penalty(sound.shape[0], real_sound, fake_sound)\n",
        "                  # Add the gradient penalty to the original discriminator loss\n",
        "                  d_loss = d_cost + gp * self.gp_weight\n",
        "\n",
        "                # Get the gradients w.r.t the discriminator loss\n",
        "                d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "                # Update the weights of the discriminator using the discriminator optimizer\n",
        "                self.d_optimizer.apply_gradients(\n",
        "                  zip(d_gradient, self.discriminator.trainable_variables)\n",
        "                )\n",
        "\n",
        "            # Train the generator now.\n",
        "            # Get the latent vector\n",
        "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "            with tf.GradientTape() as tape:\n",
        "                generated_sound = self.generator(random_latent_vectors, training=True)\n",
        "                gen_sound_logits = self.discriminator(generated_sound, training=True)\n",
        "                g_loss = self.g_loss_fn(gen_sound_logits)\n",
        "\n",
        "            # Get the gradients w.r.t the generator loss\n",
        "            gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "            # Update the weights of the generator using the generator optimizer\n",
        "            self.g_optimizer.apply_gradients(\n",
        "                zip(gen_gradient, self.generator.trainable_variables)\n",
        "            )\n",
        "            d_hist.append(float(d_loss.numpy()))\n",
        "            g_hist.append(float(g_loss.numpy()))\n",
        "            print(\"d_loss: %f , g_loss: %f\" %(d_loss, g_loss))\n",
        "            # plot_history(d_hist,g_hist,j+1) \n",
        "            if (j+1) % (bat_per_epo//3) == 0:\n",
        "              generate_and_save_images(self.generator,len(d_hist))\n",
        "              plot_history(d_hist,g_hist,len(d_hist)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVERDyfh4BlY"
      },
      "source": [
        "# Optimizer for both the networks\n",
        "# learning_rate=0.0002, beta_1=0.5 are recommened\n",
        "generator_optimizer = keras.optimizers.Adam(\n",
        "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AWFwICP8Ttb"
      },
      "source": [
        "discriminator_optimizer = keras.optimizers.Adam(\n",
        "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiWZOFD-4Hkf"
      },
      "source": [
        "# Define the loss functions to be used for discrimiator\n",
        "# This should be (fake_loss - real_loss)\n",
        "# We will add the gradient penalty later to this loss function\n",
        "def discriminator_loss(real, fake):\n",
        "    real_loss = tf.reduce_mean(real)\n",
        "    fake_loss = tf.reduce_mean(fake)\n",
        "    return fake_loss - real_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt6g8ILd8Rrk"
      },
      "source": [
        "# Define the loss functions to be used for generator\n",
        "def generator_loss(fake):\n",
        "    return -tf.reduce_mean(fake)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p_J_fEZ4M3n"
      },
      "source": [
        "# Epochs to train\n",
        "epochs = 1\n",
        "\n",
        "# Get the wgan model\n",
        "wgan = WGAN(\n",
        "    discriminator=d_model,\n",
        "    generator=g_model,\n",
        "    latent_dim=z_dim,\n",
        "    discriminator_extra_steps=5,\n",
        ")\n",
        "\n",
        "# Compile the wgan model\n",
        "wgan.compile(\n",
        "    d_optimizer=discriminator_optimizer,\n",
        "    g_optimizer=generator_optimizer,\n",
        "    g_loss_fn=generator_loss,\n",
        "    d_loss_fn=discriminator_loss,\n",
        ")\n",
        "\n",
        "# wgan.train(db_iter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq7ibAze8qh7"
      },
      "source": [
        "checkpoint_dir = '/content/gdrive/My Drive/WGANGP'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(wgan=wgan)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsFD44Lv9B3b"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfDWb7tz9EJV"
      },
      "source": [
        "checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eztV4jpC6s6"
      },
      "source": [
        "print(wgan.d_optimizer)\n",
        "print(wgan.g_optimizer)\n",
        "print(wgan.discriminator)\n",
        "print(wgan.generator)\n",
        "print(wgan.latent_dim)\n",
        "print(wgan.d_steps)\n",
        "print(wgan.gp_weight)\n",
        "print(wgan.g_loss_fn)\n",
        "print(wgan.d_loss_fn)\n",
        "print(wgan.train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1eyTBdN1bCk"
      },
      "source": [
        "wgan.generator.save(\"/content/gdrive/My Drive/WGANGP/cmodel\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPhkZR8jK42X"
      },
      "source": [
        "plot_history(d_hist,g_hist,-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ49GKOy6ufR"
      },
      "source": [
        "generate_and_save_images(wgan.generator,-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KIfa5N2Egfg"
      },
      "source": [
        "wgan.train(db_iter,n_epoch=5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}